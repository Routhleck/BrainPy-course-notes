{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1: BrainPy programming basics homework\n",
    "This is the first assignment for this course. The assignment is to familiarize themselves with the basic programming of BrainPy that was covered in class, and the participants will need to fill in the missing content according to the code comments and execute the cells to observe the results.\n",
    "\n",
    "First of all, we need to import all the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\13107\\.conda\\envs\\brainpy\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import brainpy as bp\n",
    "import brainpy.math as bm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. JIT compilation\n",
    "Just-in-time compilation is the basic technique that gaurantee the efficiency of BrainPy. In this section, we will show the basic usages of JIT compilation and experience the improvement on running performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Functional JIT compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the function. Suppose we implement a Gaussian Error Linear Unit (GELU) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "  sqrt = bm.sqrt(2 / bm.pi)\n",
    "  cdf = 0.5 * (1.0 + bm.tanh(sqrt * (x + 0.044715 * (x ** 3))))\n",
    "  y = x * cdf\n",
    "  return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the execution time without JIT compilation first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271 µs ± 5.8 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = bm.random.random(100000)\n",
    "%timeit gelu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use JIT compilation and pass the function into bm.jit(), the execution time of the function will be significantly reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.4 µs ± 1.14 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# TODO: JIT compile the gelu function using the brainpy.math library\n",
    "# Hint: Use the bm.jit()\n",
    "gelu_jit = bm.jit(gelu)\n",
    "%timeit gelu_jit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Object-oriented JIT compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the logistic regression classifier as an example, in this model, since the weight $w$ needs to be modified during training, it needs to be defined as ``brainpy.math.Variable``, and the rest of the parameters will be treated as static variables during compilation, and their values will not be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(bp.BrainPyObject):\n",
    "    def __init__(self, dimension):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "\n",
    "        # parameters\n",
    "        self.dimension = dimension\n",
    "\t\t\t\n",
    "        # variables\n",
    "        self.w = bm.Variable(2.0 * bm.ones(dimension) - 1.3)\n",
    "      \n",
    "    def __call__(self, X, Y):\n",
    "        u = bm.dot(((1.0 / (1.0 + bm.exp(-Y * bm.dot(X, self.w))) - 1.0) * Y), X)\n",
    "        self.w.value = self.w - u # in-place update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the execution time, we write a function that calculates the execution time and define the dataset:."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benckmark(model, points, labels, num_iter=30, name=''):\n",
    "    t0 = time.time()\n",
    "    for i in range(num_iter):   \n",
    "        model(points, labels)\n",
    "    print(f'{name} used time {time.time() - t0} s')\n",
    "          \n",
    "num_dim, num_points = 10, 20000000\n",
    "points = bm.random.random((num_points, num_dim))\n",
    "labels = bm.random.random(num_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's test the execution time without JIT compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (without jit) used time 6.1427717208862305 s\n"
     ]
    }
   ],
   "source": [
    "lr1 = LogisticRegression(num_dim)\n",
    "benckmark(lr1, points, labels, name='Logistic Regression (without jit)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['LogisticRegression3.w'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1 = bm.jit(LogisticRegression(num_dim))\n",
    "lr1.vars().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we test the execution time for the case of JIT compilation, which is used in a similar way to a function, simply passing the class instance into ``brainpy.math.jit()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (with jit) used time 3.892348289489746 s\n"
     ]
    }
   ],
   "source": [
    "lr2 = LogisticRegression(num_dim)\n",
    "# TODO: JIT compile the gelu function using the brainpy.math library\n",
    "# Hint: Use the bm.jit()\n",
    "lr2 = bm.jit(lr2)\n",
    "benckmark(lr2, points, labels, name='Logistic Regression (with jit)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data structures\n",
    "### 2.1 Arrays\n",
    "An array is a data structure that organizes algebraic objects in a multi-dimensional vector space. Simply put, in BrainPy, this data structure is a multidimensional array of the same data type, most commonly numeric or boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(value=Array([0, 1, 2, 3, 4, 5]), dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_array = bm.array([0, 1, 2, 3, 4, 5])\n",
    "np_array = np.array([0, 1, 2, 3, 4, 5])\n",
    "bm_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a high-dimensional array and check the properties of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2.ndim: 1\n",
      "t2.shape: (6,)\n",
      "t2.size: 6\n",
      "t2.dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a new brainpy array name t2\n",
    "t2 = bm.array([0, 1, 2, 3, 4, 5])\n",
    "print('t2.ndim: {}'.format(t2.ndim))\n",
    "print('t2.shape: {}'.format(t2.shape))\n",
    "print('t2.size: {}'.format(t2.size))\n",
    "print('t2.dtype: {}'.format(t2.dtype))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array created by ``brainty.math`` will be stored in a JaxArray, which internally holds the JAX data format DeviceArray. if the user wants to unwrap the JaxArray to get the JAX data type DeviceArray inside, simply perform the ``.value`` operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2_value: [0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Get value from t2\n",
    "t2_value = t2.value\n",
    "print('t2_value: {}'.format(t2_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dynamic variable is a pointer to an array of values (DeviceArray) stored in memory. The data in a dynamic variable can be modified during JIT compilation. If an array is declared as a dynamic variable, it means that it is an array that changes dynamically over time. To convert an array to a dynamic variable, the user simply wraps the array in `brainpy.math`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = bm.arange(4)\n",
    "# TODO: Convert t to Variable\n",
    "v = bm.Variable(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since dynamic variables are stored as arrays, all operations on arrays can be grafted directly onto dynamic variables. In addition, dynamic variables can be modified by the user, and in the next section, we will explain in detail how to modify dynamic variables under JIT compilation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing and slicing \n",
    "Users can use indexes to modify data in dynamic variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable(value=Array([10,  1,  2,  3]), dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = bm.Variable(bm.arange(4))\n",
    "# TODO: Set the first element of v to 10\n",
    "v[0] = 10\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmented assignment\n",
    "All incremental assignments in Python modify only the internal value of a dynamic variable, so you can use incremental assignments without worrying about updating dynamic variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(value=Array([11,  2,  3,  4]), dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: all the elements in v add 1\n",
    "v = v + 1\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.value` assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the most common operations for updating variables in place. We often need to assign an array of values to a dynamic variable when updating it, and a common scenario is to reset the value of a dynamic variable during an iterative update of the dynamics system. In this case, we can use the `.value` assignment operation to override the data of the dynamic variable v, which has direct access to the data stored in the JaxArray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(value=Array([0, 0, 0, 0]), dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: reset all the elements in v to 0\n",
    "v[:] = 0\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.update` assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is functionally similar to `.value `assignment and is another method provided by BrainPy to override dynamic variables, which also requires that the shape and element types of the array be consistent with the dynamic variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(value=Array([3, 4, 5, 6]), dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: set v to be [3, 4, 5, 6]\n",
    "v[:] = [3, 4, 5, 6]\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Control flows\n",
    "### 3.1 If-else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilation errors occur when conditional judgment depends on dynamic variables. Our error message will tell you about alternative solutions, so here are two ways to write a conditional statement that can be used instead of an if-else statement.\n",
    "\n",
    "First we check out the simple example that will occur compilation error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OddEvenCauseError(bp.BrainPyObject):\n",
    "    def __init__(self):\n",
    "        super(OddEvenCauseError, self).__init__()\n",
    "        self.rand = bm.Variable(bm.random.random(1))\n",
    "        self.a = bm.Variable(bm.zeros(1))\n",
    "\n",
    "    def __call__(self):\n",
    "        if self.rand < 0.5:  \n",
    "            self.a += 1\n",
    "        else:  \n",
    "            self.a -= 1\n",
    "        return self.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TracerBoolConversionError: Attempted boolean conversion of traced array with shape bool[1]..\n",
      "The error occurred while tracing the function <unknown> for eval_shape. This value became a tracer due to JAX operations on these lines:\n",
      "\n",
      "  operation a\u001b[35m:f32[]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=False] b\n",
      "    from line C:\\Users\\13107\\AppData\\Roaming\\Python\\Python310\\site-packages\\brainpy\\_src\\math\\ndarray.py:253 (__lt__)\n",
      "\n",
      "  operation a\u001b[35m:bool[1]\u001b[39m = lt b c\n",
      "    from line C:\\Users\\13107\\AppData\\Roaming\\Python\\Python310\\site-packages\\brainpy\\_src\\math\\ndarray.py:253 (__lt__)\n",
      "See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError\n"
     ]
    }
   ],
   "source": [
    "wrong_model = bm.jit(OddEvenCauseError())\n",
    "\n",
    "try:\n",
    "    wrong_model()\n",
    "except Exception as e:\n",
    "    print(f\"{e.__class__.__name__}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `brainpy.math.where()`\n",
    "This function in NumPy corresponds to `numpy.where()`, where(condition, x, y) function According to the condition to determine the true or false, the condition is true to return x, the condition is false to return y. We can change the above example of failure to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OddEvenWhere(bp.BrainPyObject):\n",
    "    def __init__(self):\n",
    "        super(OddEvenWhere, self).__init__()\n",
    "        self.rand = bm.Variable(bm.random.random(1))\n",
    "        self.a = bm.Variable(bm.zeros(1))\n",
    "\n",
    "    def __call__(self):\n",
    "        # TODO: Use bm.where() to fix the error\n",
    "        self.a = bm.where(self.rand < 0.5, self.a + 1, self.a - 1)\n",
    "        return self.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable(value=Array([-1.]), dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = bm.jit(OddEvenWhere())\n",
    "model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `brainpy.math.ifelse()`\n",
    "BrainPy provides a generic conditional statement that enables multiple branches. You need to change this example to the `bm.ifelse` statement version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OddEvenCond(bp.BrainPyObject):\n",
    "    def __init__(self):\n",
    "        super(OddEvenCond, self).__init__()\n",
    "        self.rand = bm.Variable(bm.random.random(1))\n",
    "        self.a = bm.Variable(bm.zeros(1))\n",
    "\n",
    "    def __call__(self):\n",
    "        # TODO: Use bm.ifelse() to fix the error\n",
    "        # self.a += bm.ifelse(self.rand < 0.5, \n",
    "        #                     lambda _: 1., lambda _: -1.)\n",
    "        self.a += bm.ifelse(self.rand[0] < 0.5,\n",
    "                            [lambda: 1., lambda : -1.])\n",
    "        \n",
    "        return self.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OddEvenCond.__call__.<locals>.<lambda>() missing 1 required positional argument: '_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m bm\u001b[39m.\u001b[39mjit(OddEvenCond())\n\u001b[1;32m----> 2\u001b[0m model()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\brainpy\\_src\\math\\object_transform\\jit.py:139\u001b[0m, in \u001b[0;36mJITTransform.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# initialize the transformation\u001b[39;00m\n\u001b[0;32m    138\u001b[0m   \u001b[39mwith\u001b[39;00m new_transform(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dyn_vars, rets \u001b[39m=\u001b[39m evaluate_dyn_vars(\n\u001b[0;32m    140\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfun,\n\u001b[0;32m    141\u001b[0m       \u001b[39m*\u001b[39margs,\n\u001b[0;32m    142\u001b[0m       static_argnums\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_static_argnums,\n\u001b[0;32m    143\u001b[0m       static_argnames\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_static_argnames,\n\u001b[0;32m    144\u001b[0m       use_eval_shape\u001b[39m=\u001b[39mcurrent_transform_number() \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m    145\u001b[0m       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    146\u001b[0m     )\n\u001b[0;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mjit(\n\u001b[0;32m    148\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_function,\n\u001b[0;32m    149\u001b[0m       static_argnums\u001b[39m=\u001b[39mjax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mtree_map(\u001b[39mlambda\u001b[39;00m a: a \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_static_argnums),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m       out_shardings\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_out_shardings,\n\u001b[0;32m    157\u001b[0m     )\n\u001b[0;32m    159\u001b[0m   \u001b[39m# if not the outermost transformation\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\brainpy\\_src\\math\\object_transform\\_tools.py:97\u001b[0m, in \u001b[0;36mevaluate_dyn_vars\u001b[1;34m(f, static_argnums, static_argnames, use_eval_shape, *args, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mwith\u001b[39;00m VariableStack() \u001b[39mas\u001b[39;00m stack:\n\u001b[0;32m     96\u001b[0m   \u001b[39mif\u001b[39;00m use_eval_shape:\n\u001b[1;32m---> 97\u001b[0m     rets \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39meval_shape(f2, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     98\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     99\u001b[0m     rets \u001b[39m=\u001b[39m f2(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "    \u001b[1;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[48], line 11\u001b[0m, in \u001b[0;36mOddEvenCond.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \u001b[39m# TODO: Use bm.ifelse() to fix the error\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[39m# self.a += bm.ifelse(self.rand < 0.5, \u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[39m#                     lambda _: 1., lambda _: -1.)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ma \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m bm\u001b[39m.\u001b[39;49mifelse([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrand[\u001b[39m0\u001b[39;49m] \u001b[39m<\u001b[39;49m \u001b[39m0.5\u001b[39;49m], [\u001b[39mlambda\u001b[39;49;00m _: \u001b[39m1.\u001b[39;49m, \u001b[39mlambda\u001b[39;49;00m _: \u001b[39m-\u001b[39;49m\u001b[39m1.\u001b[39;49m], operands\u001b[39m=\u001b[39;49m())\n\u001b[0;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ma\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\brainpy\\_src\\math\\object_transform\\controls.py:665\u001b[0m, in \u001b[0;36mifelse\u001b[1;34m(conditions, branches, operands, show_code, dyn_vars, child_objs)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[39m# format new codes\u001b[39;00m\n\u001b[0;32m    664\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(conditions) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 665\u001b[0m   \u001b[39mreturn\u001b[39;00m cond(conditions[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m    666\u001b[0m               branches[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m    667\u001b[0m               branches[\u001b[39m1\u001b[39;49m],\n\u001b[0;32m    668\u001b[0m               operands)\n\u001b[0;32m    669\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    670\u001b[0m   \u001b[39mif\u001b[39;00m jax\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mjax_disable_jit:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\brainpy\\_src\\math\\object_transform\\controls.py:539\u001b[0m, in \u001b[0;36mcond\u001b[1;34m(pred, true_fun, false_fun, operands, dyn_vars, child_objs)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[39mif\u001b[39;00m dyn_vars \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    538\u001b[0m   \u001b[39mwith\u001b[39;00m new_transform(\u001b[39m'\u001b[39m\u001b[39mcond\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 539\u001b[0m     dyn_vars, rets \u001b[39m=\u001b[39m evaluate_dyn_vars(\n\u001b[0;32m    540\u001b[0m       _transform,\n\u001b[0;32m    541\u001b[0m       operands,\n\u001b[0;32m    542\u001b[0m       use_eval_shape\u001b[39m=\u001b[39;49mcurrent_transform_number() \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m\n\u001b[0;32m    543\u001b[0m     )\n\u001b[0;32m    544\u001b[0m     cache_stack((true_fun, false_fun), dyn_vars)\n\u001b[0;32m    545\u001b[0m   \u001b[39mif\u001b[39;00m current_transform_number() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\brainpy\\_src\\math\\object_transform\\_tools.py:99\u001b[0m, in \u001b[0;36mevaluate_dyn_vars\u001b[1;34m(f, static_argnums, static_argnames, use_eval_shape, *args, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m     rets \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39meval_shape(f2, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     98\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 99\u001b[0m     rets \u001b[39m=\u001b[39m f2(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    100\u001b[0m \u001b[39mreturn\u001b[39;00m stack, rets\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\brainpy\\_src\\math\\object_transform\\controls.py:452\u001b[0m, in \u001b[0;36m_get_cond_transform.<locals>.call_fun\u001b[1;34m(operands)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_fun\u001b[39m(operands):\n\u001b[1;32m--> 452\u001b[0m   \u001b[39mreturn\u001b[39;00m jax\u001b[39m.\u001b[39;49mlax\u001b[39m.\u001b[39;49mcond(pred, _true_fun, _false_fun, dyn_vars\u001b[39m.\u001b[39;49mdict_data(), \u001b[39m*\u001b[39;49moperands)\n",
      "    \u001b[1;31m[... skipping hidden 13 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\brainpy\\_src\\math\\object_transform\\controls.py:441\u001b[0m, in \u001b[0;36m_cond_transform_fun.<locals>.new_fun\u001b[1;34m(dyn_vals, *static_vals)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m dyn_vars\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    440\u001b[0m   v\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m dyn_vals[k]\n\u001b[1;32m--> 441\u001b[0m r \u001b[39m=\u001b[39m fun(\u001b[39m*\u001b[39;49mstatic_vals)\n\u001b[0;32m    442\u001b[0m \u001b[39mreturn\u001b[39;00m {k: v\u001b[39m.\u001b[39mvalue \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m dyn_vars\u001b[39m.\u001b[39mitems()}, r\n",
      "\u001b[1;31mTypeError\u001b[0m: OddEvenCond.__call__.<locals>.<lambda>() missing 1 required positional argument: '_'"
     ]
    }
   ],
   "source": [
    "model = bm.jit(OddEvenCond())\n",
    "model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, BrainPy can write loops in Python mode. The user simply iterates over the sequence data and then operates on the iterated objects. This loop syntax is compatible with JIT compilation, but can lead to long tracing and compilation times. The following example is a class object that implement for loop in its function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoopSimple(bp.BrainPyObject):\n",
    "    def __init__(self):\n",
    "        super(LoopSimple, self).__init__()\n",
    "        rng = bm.random.RandomState(123)\n",
    "        self.seq = bm.Variable(rng.random(1000))\n",
    "        self.res = bm.Variable(bm.zeros(1))\n",
    "\n",
    "    def __call__(self):\n",
    "        for s in self.seq:\n",
    "            self.res += s\n",
    "        return self.res.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the following code, we will find that the first compilation takes longer, and if the logic of the statements in the program is more complex, the compilation will take an intolerable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def measure_time(f, return_res=False, verbose=True):\n",
    "    t0 = time.time()\n",
    "    r = f()\n",
    "    t1 = time.time()\n",
    "    if verbose:\n",
    "        print(f'Result: {r}, Time: {t1 - t0}')\n",
    "    return r if return_res else None\n",
    "\n",
    "model = bm.jit(LoopSimple())\n",
    "\n",
    "# First time will trigger compilation\n",
    "measure_time(model)\n",
    "\n",
    "# Second running\n",
    "measure_time(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `brainpy.math.for_loop()`\n",
    "We speed up the code by using structured looping statements, you need to fill the blank in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoopStruct(bp.BrainPyObject):\n",
    "    def __init__(self):\n",
    "        super(LoopStruct, self).__init__()\n",
    "        rng = bm.random.RandomState(123)\n",
    "        self.seq = rng.random(1000)\n",
    "        self.res = bm.Variable(bm.zeros(1))\n",
    "\n",
    "    def __call__(self):\n",
    "        # TODO: Use bm.for_loop() to complete the loop\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bm.jit(LoopStruct())\n",
    "\n",
    "r = measure_time(model, verbose=False, return_res=True)\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solutions\n",
    "# Functional JIT compilation: \n",
    "gelu_jit = bm.jit(gelu)\n",
    "\n",
    "# Object-oriented JIT compilation:\n",
    "lr2 = bm.jit(lr2)\n",
    "\n",
    "# Create arrays:\n",
    "t2 = bm.array([[[0, 1, 2, 3], [1, 2, 3, 4], [4, 5, 6, 7]],\n",
    "               [[0, 0, 0, 0], [-1, 1, -1, 1], [2, -2, 2, -2]]])\n",
    "\n",
    "\n",
    "# Get values of arrays:\n",
    "t2_value = t2.value\n",
    "\n",
    "# Convert to variable:\n",
    "v = bm.Variable(t)\n",
    "\n",
    "# Indexing and slicing:\n",
    "v[0] = 10\n",
    "\n",
    "# Augmented assignment:\n",
    "v += 1\n",
    "\n",
    "# .value assignment:\n",
    "v.value = bm.zeros(4)\n",
    "\n",
    "# .update assignment:\n",
    "v.update(bm.array([3, 4, 5, 6]))\n",
    "\n",
    "# where condition:\n",
    "class OddEvenWhere(bp.BrainPyObject):\n",
    "    def __init__(self):\n",
    "        super(OddEvenWhere, self).__init__()\n",
    "        self.rand = bm.Variable(bm.random.random(1))\n",
    "        self.a = bm.Variable(bm.zeros(1))\n",
    "\n",
    "    def __call__(self):\n",
    "        self.a += bm.where(self.rand < 0.5, 1., -1.)\n",
    "        return self.a\n",
    "\n",
    "# ifelse condition:\n",
    "class OddEvenCond(bp.BrainPyObject):\n",
    "    def __init__(self):\n",
    "        super(OddEvenCond, self).__init__()\n",
    "        self.rand = bm.Variable(bm.random.random(1))\n",
    "        self.a = bm.Variable(bm.zeros(1))\n",
    "\n",
    "    def __call__(self):\n",
    "        self.a += bm.ifelse(self.rand[0] < 0.5,\n",
    "                            [lambda _: 1., lambda _: -1.])\n",
    "        return self.a\n",
    "\n",
    "# For loop:\n",
    "class LoopStruct(bp.BrainPyObject):\n",
    "    def __init__(self):\n",
    "        super(LoopStruct, self).__init__()\n",
    "        rng = bm.random.RandomState(123)\n",
    "        self.seq = rng.random(1000)\n",
    "        self.res = bm.Variable(bm.zeros(1))\n",
    "\n",
    "    def __call__(self):\n",
    "        def add(s):\n",
    "          self.res += s\n",
    "          return self.res.value\n",
    "\n",
    "        return bm.for_loop(body_fun=add, operands=self.seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
